{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from IPython.core.display import HTML\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reading the abstracts in to a Dataframes\n",
    "mfgDf = pd.DataFrame.from_csv('../../data/positive_data.csv', index_col=None)\n",
    "nsfDf = pd.DataFrame.from_csv('../../data/negative_data.csv', index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#draw samples of 1000 from MFG and NON-MFG and add the flags\n",
    "mfgDfSample = mfgDf.sample(1000)\n",
    "mfgDfSample[\"sample_type\"] = \"MFG\"\n",
    "\n",
    "nsfDfSample = nsfDf.sample(1000)\n",
    "nsfDfSample[\"sample_type\"] = \"NON-MFG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#merging two dataframes to get a master data frame\n",
    "#from which we will draw train and test samples\n",
    "df = mfgDfSample.append(nsfDfSample)\n",
    "df[\"txt\"] = df[\"title\"] + \" \" + df[\"abstract\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#creating training and test hold out set\n",
    "from sklearn.cross_validation import train_test_split\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(df['txt'].values.astype('U'), \n",
    "                                              (df[\"sample_type\"]==\"MFG\").values,random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#count vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer =  CountVectorizer(ngram_range=(1, 2),token_pattern=r'\\b\\w+\\b', min_df=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#creating a vect tranformer and vectorizing the training corpus\n",
    "corpus = Xtrain\n",
    "vectorizer = vectorizer.fit(corpus)\n",
    "X = vectorizer.transform(corpus)\n",
    "feature_names = np.asarray(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 230406)"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fitting a tfidf tranformer and tranforming the vector\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "transformer = TfidfTransformer()\n",
    "tfidf_transformer = transformer.fit(X.toarray())\n",
    "tfidf = tfidf_transformer.transform(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#training X and y\n",
    "X_tfidf = tfidf.toarray()\n",
    "y_target = ytrain\n",
    "\n",
    "#hold out/test X and y\n",
    "X_test_tfidf = tfidf_transformer.transform(vectorizer.transform(Xtest).toarray()).toarray()\n",
    "y_test_target = ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Dimensionality Reduction ### Is this the right way for dimensionality reduction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dimensionality reduction using Univariate statistics/selectKBest chi2\n",
    "#http://scikit-learn.org/stable/modules/feature_selection.html\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "skb = SelectKBest(chi2, k=4000)\n",
    "\n",
    "#creating training and test X for dimensionaly reduced data\n",
    "X_dr_train = skb.fit_transform(X_tfidf, y_target)\n",
    "X_dr_test = skb.transform(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_names_dr = []\n",
    "feature_names_dr = [ feature_names[i] for i in skb.get_support(indices=True)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.862\n"
     ]
    }
   ],
   "source": [
    "#performing logistic regression on the data\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_tfidf,ytrain)\n",
    "from sklearn.metrics import accuracy_score\n",
    "#calculating accuracy of the classifier\n",
    "print(accuracy_score(clf.predict(X_test_tfidf),y_test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.854\n"
     ]
    }
   ],
   "source": [
    "#performing logistic regression on the dimensionally reduced data\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf_dr = LogisticRegression()\n",
    "clf_dr.fit(X_dr_train,y_target)\n",
    "#calculating accuracy of the classifier\n",
    "print(accuracy_score(clf_dr.predict(X_dr_test),y_test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############################################################################\n",
    "### Using Multinomial classifier\n",
    "############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85399999999999998"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#performing multinomial NB on data\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf_mn = MultinomialNB()\n",
    "clf_mn.fit(X_tfidf, y_target)\n",
    "accuracy_score(clf_mn.predict(X_test_tfidf), y_test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.874\n"
     ]
    }
   ],
   "source": [
    "#performing multinomial NB on reduced data\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf_mn_dr = MultinomialNB()\n",
    "clf_mn_dr.fit(X_dr_train, y_target)\n",
    "print(accuracy_score(clf_mn_dr.predict(X_dr_test),y_test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############################################################################\n",
    "### Using SGD classifier\n",
    "############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.874"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#performing SGDClassifier on data\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "clf_sgd = SGDClassifier()\n",
    "clf_sgd.fit(X_tfidf, y_target)\n",
    "accuracy_score(clf_sgd.predict(X_test_tfidf), y_test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82199999999999995"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#performing SGDClassifier on reduced data\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "clf_sgd_dr = SGDClassifier()\n",
    "clf_sgd_dr.fit(X_dr_train, y_target)\n",
    "accuracy_score(clf_sgd_dr.predict(X_dr_test), y_test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "############################################################################\n",
    "### trying the pipeline using Multinomial classifier\n",
    "############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.846\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf_mn_pl = Pipeline([('vect', CountVectorizer()),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf', MultinomialNB()),\n",
    " ])\n",
    "clf_mn_pl = clf_mn_pl.fit(Xtrain, ytrain)\n",
    "print(accuracy_score(clf_mn_pl.predict(Xtest),ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.844\n"
     ]
    }
   ],
   "source": [
    "#with dimensionality reduction????????? Not sure if this is the right way to pass parameters.\n",
    "clf_mn_pl_dr = Pipeline([('vect', CountVectorizer()),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf', MultinomialNB()),\n",
    " ])\n",
    "\n",
    "'''ps = {\n",
    "    'vect__max_features': (None, 5000, 10000, 50000),\n",
    "    'vect__ngram_range': ((1, 1))  # unigrams or bigrams    \n",
    "    }\n",
    "    '''\n",
    "#clf_mn_pl_dr.set_params(vect__max_features=10000)\n",
    "clf_mn_pl_dr = clf_mn_pl_dr.set_params(vect__max_features=10000).fit(Xtrain, ytrain)\n",
    "print(accuracy_score(clf_mn_pl_dr.predict(Xtest),ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############################################################################\n",
    "### trying the pipeline using SGD classifier\n",
    "############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.878"
      ]
     },
     "execution_count": 515,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "text_clf_sg = Pipeline([('vect', CountVectorizer()),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                            alpha=1e-3, n_iter=5, random_state=42)),\n",
    " ])\n",
    "text_clf_sg = text_clf_sg.fit(Xtrain, ytrain)\n",
    "predicted = text_clf_sg.predict(Xtest)\n",
    "np.mean(predicted == ytest)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.85      0.90      0.88       242\n",
      "       True       0.90      0.86      0.88       258\n",
      "\n",
      "avg / total       0.88      0.88      0.88       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# reading the metrics\n",
    "from sklearn import metrics\n",
    "print(metrics.classification_report(ytest, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[218,  24],\n",
       "       [ 37, 221]])"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## reading the confusion matrix\n",
    "metrics.confusion_matrix(ytest, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Parameter tuning using grid search             #\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "'''\n",
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "               'tfidf__use_idf': (True, False),\n",
    "               'clf__alpha': (1e-2, 1e-3),\n",
    "}\n",
    "'''\n",
    "\n",
    "parameters = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    'vect__max_features': (None, 5000, 10000, 50000),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "    #'tfidf__use_idf': (True),\n",
    "    #'tfidf__norm': ('l1', 'l2'),\n",
    "    'clf__alpha': (0.00001, 0.000001),\n",
    "    'clf__penalty': ('l2', 'elasticnet'),\n",
    "    'clf__n_iter': (10, 50, 80),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gs_clf = GridSearchCV(text_clf_sg, parameters, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gs_clf = gs_clf.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf__alpha: 1e-05\n",
      "clf__n_iter: 50\n",
      "clf__penalty: 'elasticnet'\n",
      "vect__max_df: 0.75\n",
      "vect__max_features: None\n",
      "vect__ngram_range: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "best_parameters, score, _ = max(gs_clf.grid_scores_, key=lambda x: x[1])\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87133333333333329"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88800000000000001"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gspredicted = gs_clf.predict(Xtest)\n",
    "np.mean(gspredicted == ytest)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
