{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from IPython.core.display import HTML\n",
    "import matplotlib.pyplot as plt\n",
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def freq(word, tokens):\n",
    "    return tokens.count(word)\n",
    "\n",
    "def word_count(tokens):\n",
    "    return len(tokens)\n",
    "\n",
    "def tf(word, tokens):\n",
    "    return (freq(word, tokens) / float(word_count(tokens)))\n",
    "\n",
    "def getFreqByDoc(doc):\n",
    "    #get tokens\n",
    "    tokens = nltk.word_tokenize(str(doc[1]) + ' ' + str(doc[2]))\n",
    "    \n",
    "    #get bitokens\n",
    "    bi_tokens =  nltk.bigrams(tokens)\n",
    "    bi_tokens = [' '.join(token).lower() for token in bi_tokens]\n",
    "    bi_tokens = [token for token in bi_tokens if token not in stopwords]\n",
    "\n",
    "    tokens = [token.lower() for token in tokens if len(token) > 2]\n",
    "    tokens = [token for token in tokens if token not in stopwords]\n",
    "\n",
    "    #merge tokens and bi\n",
    "    alltokens = []\n",
    "    alltokens.extend(tokens)\n",
    "    alltokens.extend(bi_tokens)\n",
    "\n",
    "    wc = word_count(tokens)\n",
    "    olist = []\n",
    "    for token in (alltokens):\n",
    "        f = freq(token, alltokens)\n",
    "        ilist = [doc[0], token, f, wc, f/float(wc), doc[3], doc[5]]\n",
    "        olist.append(ilist)\n",
    "    df = pd.DataFrame(olist, columns=['doc','word', 'frequency', 'word_count', 'tf','source', 'sample_type'])\n",
    "    return df\n",
    "\n",
    "def createFreqCSV(sdf, filename):\n",
    "    mfgDfSampleList = sdf.as_matrix().tolist()\n",
    "    for mfg in mfgDfSampleList:\n",
    "        df = getFreqByDoc(mfg)\n",
    "        with open(filename, 'a') as f:\n",
    "            df.to_csv(f, header=False , index=False)    \n",
    "    return\n",
    "\n",
    "def createFreqDf(sdf):\n",
    "    #pass a sample df\n",
    "    #make a list so that it can be iterated\n",
    "    mfgDfSampleList = sdf.as_matrix().tolist()\n",
    "    mfgFreqDfList = []\n",
    "    for mfg in mfgDfSampleList:\n",
    "        df = getFreqByDoc(mfg)\n",
    "        mfgFreqDfList.append(df)\n",
    "\n",
    "    mfgFreqDf = pd.concat(mfgFreqDfList)\n",
    "    return mfgFreqDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#reading the abstracts in to a DF\n",
    "mfgDf = pd.DataFrame.from_csv('../../data/positive_data.csv', index_col=None)\n",
    "nsfDf = pd.DataFrame.from_csv('../../data/negative_data.csv', index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#draw samples\n",
    "mfgDfSample = mfgDf.sample(1000)\n",
    "mfgDfSample[\"sample_type\"] = \"MFG\"\n",
    "\n",
    "nsfDfSample = nsfDf.sample(1000)\n",
    "nsfDfSample[\"sample_type\"] = \"NON-MFG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>event_name</th>\n",
       "      <th>event_year</th>\n",
       "      <th>sample_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2185</th>\n",
       "      <td>NSF_20140101_1462280</td>\n",
       "      <td>CHS: Medium: Collaborative Research: Immediate...</td>\n",
       "      <td>American Sign Language (ASL) is a primary mean...</td>\n",
       "      <td>NSF</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>MFG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4080</th>\n",
       "      <td>CIRP_20120101_383-386</td>\n",
       "      <td>Raw part characterisation and automated alignm...</td>\n",
       "      <td>Large raw parts require a long time consuming ...</td>\n",
       "      <td>CIRP</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>MFG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2627</th>\n",
       "      <td>NSF_20150101_1536918</td>\n",
       "      <td>Household-Level Use of Autonomous Vehicles: Mo...</td>\n",
       "      <td>With recent development in vehicle automation,...</td>\n",
       "      <td>NSF</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>MFG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4358</th>\n",
       "      <td>CIRP_20140101_058-1205</td>\n",
       "      <td>Alternation of analysis and synthesis for conc...</td>\n",
       "      <td>Concept generation involves both analysis and ...</td>\n",
       "      <td>CIRP</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>MFG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>NSF_20130101_1316583</td>\n",
       "      <td>Workshop on Humanitarian Logistics Research, A...</td>\n",
       "      <td>This grant provides funding to host a workshop...</td>\n",
       "      <td>NSF</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>MFG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          id  \\\n",
       "2185    NSF_20140101_1462280   \n",
       "4080   CIRP_20120101_383-386   \n",
       "2627    NSF_20150101_1536918   \n",
       "4358  CIRP_20140101_058-1205   \n",
       "466     NSF_20130101_1316583   \n",
       "\n",
       "                                                  title  \\\n",
       "2185  CHS: Medium: Collaborative Research: Immediate...   \n",
       "4080  Raw part characterisation and automated alignm...   \n",
       "2627  Household-Level Use of Autonomous Vehicles: Mo...   \n",
       "4358  Alternation of analysis and synthesis for conc...   \n",
       "466   Workshop on Humanitarian Logistics Research, A...   \n",
       "\n",
       "                                               abstract event_name  \\\n",
       "2185  American Sign Language (ASL) is a primary mean...        NSF   \n",
       "4080  Large raw parts require a long time consuming ...       CIRP   \n",
       "2627  With recent development in vehicle automation,...        NSF   \n",
       "4358  Concept generation involves both analysis and ...       CIRP   \n",
       "466   This grant provides funding to host a workshop...        NSF   \n",
       "\n",
       "      event_year sample_type  \n",
       "2185      2014.0         MFG  \n",
       "4080      2012.0         MFG  \n",
       "2627      2015.0         MFG  \n",
       "4358      2014.0         MFG  \n",
       "466       2013.0         MFG  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfgDfSample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#mfgf = createFreqDf(mfgDfSample)\n",
    "#print(mfgf)\n",
    "#nsff = createFreqDf(nsfDfSample)\n",
    "#print(nsfgf)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#positive sample raw csv\n",
    "createFreqCSV(mfgDfSample, 'C:\\\\datascience\\\\data\\\\raw\\\\positive.csv')\n",
    "#negative sample raw csv\n",
    "createFreqCSV(nsfDfSample, 'C:\\\\datascience\\\\data\\\\raw\\\\negative.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' DB Script\n",
    "\n",
    "CREATE TABLE `raw_keywords` (\n",
    "  `id` int(11) NOT NULL AUTO_INCREMENT,\n",
    "  `doc` varchar(45) DEFAULT NULL,\n",
    "  `word` varchar(145) DEFAULT NULL,\n",
    "  `frequency` int(11) DEFAULT NULL,\n",
    "  `word_count` int(11) DEFAULT NULL,\n",
    "  `tf` double DEFAULT NULL,\n",
    "  PRIMARY KEY (`id`)\n",
    ") ENGINE=InnoDB AUTO_INCREMENT=589816 DEFAULT CHARSET=latin1;\n",
    "\n",
    "truncate raw_keywords;\n",
    "\n",
    "LOAD DATA LOCAL INFILE 'C:\\\\datascience\\\\data\\\\raw\\\\positive.csv' INTO TABLE raw_keywords\n",
    "CHARACTER SET UTF8 \n",
    "FIELDS TERMINATED BY ',' \n",
    "ENCLOSED BY '\"' \n",
    "LINES TERMINATED BY '\\n'\n",
    "IGNORE 0 LINES\n",
    "(doc, word, frequency, word_count, tf);\n",
    "\n",
    "CREATE TABLE `raw_keywords_neg` (\n",
    "  `id` int(11) NOT NULL AUTO_INCREMENT,\n",
    "  `doc` varchar(45) DEFAULT NULL,\n",
    "  `word` varchar(145) DEFAULT NULL,\n",
    "  `frequency` int(11) DEFAULT NULL,\n",
    "  `word_count` int(11) DEFAULT NULL,\n",
    "  `tf` double DEFAULT NULL,\n",
    "  PRIMARY KEY (`id`)\n",
    ");\n",
    "\n",
    "truncate raw_keywords_neg;\n",
    "\n",
    "LOAD DATA LOCAL INFILE 'C:\\\\datascience\\\\data\\\\raw\\\\negative.csv' INTO TABLE raw_keywords_neg\n",
    "CHARACTER SET UTF8 \n",
    "FIELDS TERMINATED BY ',' \n",
    "ENCLOSED BY '\"' \n",
    "LINES TERMINATED BY '\\n'\n",
    "IGNORE 0 LINES\n",
    "(doc, word, frequency, word_count, tf);\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
